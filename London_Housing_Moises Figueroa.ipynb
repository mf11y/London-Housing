{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tia3MP1SJpgj"
   },
   "source": [
    "# Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEau5nEvJpgm"
   },
   "source": [
    "#### 1.1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7Bt_Q_oPJpgn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koUrawxsJpgq"
   },
   "source": [
    "#### 1.2.  Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AiLiD4v3Jpgr"
   },
   "outputs": [],
   "source": [
    "path = 'UK_House_price_index.xlsx'\n",
    "data = pd.read_excel(path, sheet_name='Average price', index_col= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Te0Q548tnzZa"
   },
   "source": [
    "**2.1. Exploring your data** \n",
    "\n",
    "Think about your pandas functions for checking out a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Rxirxw_qoAJa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>City of London</th>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>Croydon</th>\n",
       "      <th>Ealing</th>\n",
       "      <th>...</th>\n",
       "      <th>NORTH WEST</th>\n",
       "      <th>YORKS &amp; THE HUMBER</th>\n",
       "      <th>EAST MIDLANDS</th>\n",
       "      <th>WEST MIDLANDS</th>\n",
       "      <th>EAST OF ENGLAND</th>\n",
       "      <th>LONDON</th>\n",
       "      <th>SOUTH EAST</th>\n",
       "      <th>SOUTH WEST</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>England</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>...</td>\n",
       "      <td>E12000002</td>\n",
       "      <td>E12000003</td>\n",
       "      <td>E12000004</td>\n",
       "      <td>E12000005</td>\n",
       "      <td>E12000006</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>E12000008</td>\n",
       "      <td>E12000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E92000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>91449</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>81671.5</td>\n",
       "      <td>120933</td>\n",
       "      <td>69158.2</td>\n",
       "      <td>79885.9</td>\n",
       "      <td>...</td>\n",
       "      <td>43958.5</td>\n",
       "      <td>44803.4</td>\n",
       "      <td>45544.5</td>\n",
       "      <td>48527.5</td>\n",
       "      <td>56701.6</td>\n",
       "      <td>74435.8</td>\n",
       "      <td>64018.9</td>\n",
       "      <td>54705.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53202.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>81657.6</td>\n",
       "      <td>119509</td>\n",
       "      <td>68951.1</td>\n",
       "      <td>80897.1</td>\n",
       "      <td>...</td>\n",
       "      <td>43925.4</td>\n",
       "      <td>44528.8</td>\n",
       "      <td>46051.6</td>\n",
       "      <td>49341.3</td>\n",
       "      <td>56593.6</td>\n",
       "      <td>72777.9</td>\n",
       "      <td>63715</td>\n",
       "      <td>54356.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53096.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>51269</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>81449.3</td>\n",
       "      <td>120282</td>\n",
       "      <td>68712.4</td>\n",
       "      <td>81379.9</td>\n",
       "      <td>...</td>\n",
       "      <td>44434.9</td>\n",
       "      <td>45200.5</td>\n",
       "      <td>45383.8</td>\n",
       "      <td>49442.2</td>\n",
       "      <td>56171.2</td>\n",
       "      <td>73896.8</td>\n",
       "      <td>64113.6</td>\n",
       "      <td>53583.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53201.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>81124.4</td>\n",
       "      <td>120098</td>\n",
       "      <td>68610</td>\n",
       "      <td>82188.9</td>\n",
       "      <td>...</td>\n",
       "      <td>44267.8</td>\n",
       "      <td>45614.3</td>\n",
       "      <td>46124.2</td>\n",
       "      <td>49455.9</td>\n",
       "      <td>56567.9</td>\n",
       "      <td>74455.3</td>\n",
       "      <td>64623.2</td>\n",
       "      <td>54786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53590.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>747611</td>\n",
       "      <td>303653</td>\n",
       "      <td>518542</td>\n",
       "      <td>334765</td>\n",
       "      <td>423161</td>\n",
       "      <td>435532</td>\n",
       "      <td>815512</td>\n",
       "      <td>371227</td>\n",
       "      <td>466491</td>\n",
       "      <td>...</td>\n",
       "      <td>165094</td>\n",
       "      <td>164752</td>\n",
       "      <td>196199</td>\n",
       "      <td>202085</td>\n",
       "      <td>290335</td>\n",
       "      <td>478489</td>\n",
       "      <td>323422</td>\n",
       "      <td>257822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>777640</td>\n",
       "      <td>304265</td>\n",
       "      <td>519121</td>\n",
       "      <td>337760</td>\n",
       "      <td>467145</td>\n",
       "      <td>435704</td>\n",
       "      <td>825249</td>\n",
       "      <td>371357</td>\n",
       "      <td>465614</td>\n",
       "      <td>...</td>\n",
       "      <td>166291</td>\n",
       "      <td>164949</td>\n",
       "      <td>194214</td>\n",
       "      <td>200196</td>\n",
       "      <td>290309</td>\n",
       "      <td>479628</td>\n",
       "      <td>319827</td>\n",
       "      <td>257101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>844989</td>\n",
       "      <td>304099</td>\n",
       "      <td>527747</td>\n",
       "      <td>339215</td>\n",
       "      <td>461398</td>\n",
       "      <td>434625</td>\n",
       "      <td>870107</td>\n",
       "      <td>370872</td>\n",
       "      <td>478565</td>\n",
       "      <td>...</td>\n",
       "      <td>168161</td>\n",
       "      <td>165685</td>\n",
       "      <td>198284</td>\n",
       "      <td>201369</td>\n",
       "      <td>291356</td>\n",
       "      <td>488185</td>\n",
       "      <td>326701</td>\n",
       "      <td>262444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>867841</td>\n",
       "      <td>283139</td>\n",
       "      <td>526553</td>\n",
       "      <td>346840</td>\n",
       "      <td>494455</td>\n",
       "      <td>443482</td>\n",
       "      <td>870627</td>\n",
       "      <td>386738</td>\n",
       "      <td>502107</td>\n",
       "      <td>...</td>\n",
       "      <td>167809</td>\n",
       "      <td>165561</td>\n",
       "      <td>200513</td>\n",
       "      <td>202093</td>\n",
       "      <td>295640</td>\n",
       "      <td>480425</td>\n",
       "      <td>327413</td>\n",
       "      <td>255891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>899831</td>\n",
       "      <td>295744</td>\n",
       "      <td>532503</td>\n",
       "      <td>339408</td>\n",
       "      <td>466574</td>\n",
       "      <td>420036</td>\n",
       "      <td>862209</td>\n",
       "      <td>369791</td>\n",
       "      <td>490596</td>\n",
       "      <td>...</td>\n",
       "      <td>168261</td>\n",
       "      <td>170198</td>\n",
       "      <td>197505</td>\n",
       "      <td>203658</td>\n",
       "      <td>290621</td>\n",
       "      <td>479018</td>\n",
       "      <td>324659</td>\n",
       "      <td>261006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 City of London Barking & Dagenham     Barnet     Bexley  \\\n",
       "0          NaT      E09000001          E09000002  E09000003  E09000004   \n",
       "1   1995-01-01          91449            50460.2    93284.5    64958.1   \n",
       "2   1995-02-01        82202.8            51085.8    93190.2    64787.9   \n",
       "3   1995-03-01        79120.7              51269    92247.5    64367.5   \n",
       "4   1995-04-01        77101.2            53133.5    90762.9    64277.7   \n",
       "..         ...            ...                ...        ...        ...   \n",
       "301 2020-01-01         747611             303653     518542     334765   \n",
       "302 2020-02-01         777640             304265     519121     337760   \n",
       "303 2020-03-01         844989             304099     527747     339215   \n",
       "304 2020-04-01         867841             283139     526553     346840   \n",
       "305 2020-05-01         899831             295744     532503     339408   \n",
       "\n",
       "         Brent    Bromley     Camden    Croydon     Ealing  ... NORTH WEST  \\\n",
       "0    E09000005  E09000006  E09000007  E09000008  E09000009  ...  E12000002   \n",
       "1      71306.6    81671.5     120933    69158.2    79885.9  ...    43958.5   \n",
       "2      72022.3    81657.6     119509    68951.1    80897.1  ...    43925.4   \n",
       "3      72015.8    81449.3     120282    68712.4    81379.9  ...    44434.9   \n",
       "4      72965.6    81124.4     120098      68610    82188.9  ...    44267.8   \n",
       "..         ...        ...        ...        ...        ...  ...        ...   \n",
       "301     423161     435532     815512     371227     466491  ...     165094   \n",
       "302     467145     435704     825249     371357     465614  ...     166291   \n",
       "303     461398     434625     870107     370872     478565  ...     168161   \n",
       "304     494455     443482     870627     386738     502107  ...     167809   \n",
       "305     466574     420036     862209     369791     490596  ...     168261   \n",
       "\n",
       "    YORKS & THE HUMBER EAST MIDLANDS WEST MIDLANDS EAST OF ENGLAND     LONDON  \\\n",
       "0            E12000003     E12000004     E12000005       E12000006  E12000007   \n",
       "1              44803.4       45544.5       48527.5         56701.6    74435.8   \n",
       "2              44528.8       46051.6       49341.3         56593.6    72777.9   \n",
       "3              45200.5       45383.8       49442.2         56171.2    73896.8   \n",
       "4              45614.3       46124.2       49455.9         56567.9    74455.3   \n",
       "..                 ...           ...           ...             ...        ...   \n",
       "301             164752        196199        202085          290335     478489   \n",
       "302             164949        194214        200196          290309     479628   \n",
       "303             165685        198284        201369          291356     488185   \n",
       "304             165561        200513        202093          295640     480425   \n",
       "305             170198        197505        203658          290621     479018   \n",
       "\n",
       "    SOUTH EAST SOUTH WEST Unnamed: 47    England  \n",
       "0    E12000008  E12000009         NaN  E92000001  \n",
       "1      64018.9    54705.2         NaN    53202.8  \n",
       "2        63715    54356.1         NaN    53096.2  \n",
       "3      64113.6    53583.1         NaN    53201.3  \n",
       "4      64623.2      54786         NaN    53590.9  \n",
       "..         ...        ...         ...        ...  \n",
       "301     323422     257822         NaN     248950  \n",
       "302     319827     257101         NaN     248232  \n",
       "303     326701     262444         NaN     251539  \n",
       "304     327413     255891         NaN     250874  \n",
       "305     324659     261006         NaN     251973  \n",
       "\n",
       "[306 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 306 entries, 0 to 305\n",
      "Data columns (total 49 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   Unnamed: 0            305 non-null    datetime64[ns]\n",
      " 1   City of London        306 non-null    object        \n",
      " 2   Barking & Dagenham    306 non-null    object        \n",
      " 3   Barnet                306 non-null    object        \n",
      " 4   Bexley                306 non-null    object        \n",
      " 5   Brent                 306 non-null    object        \n",
      " 6   Bromley               306 non-null    object        \n",
      " 7   Camden                306 non-null    object        \n",
      " 8   Croydon               306 non-null    object        \n",
      " 9   Ealing                306 non-null    object        \n",
      " 10  Enfield               306 non-null    object        \n",
      " 11  Greenwich             306 non-null    object        \n",
      " 12  Hackney               306 non-null    object        \n",
      " 13  Hammersmith & Fulham  306 non-null    object        \n",
      " 14  Haringey              306 non-null    object        \n",
      " 15  Harrow                306 non-null    object        \n",
      " 16  Havering              306 non-null    object        \n",
      " 17  Hillingdon            306 non-null    object        \n",
      " 18  Hounslow              306 non-null    object        \n",
      " 19  Islington             306 non-null    object        \n",
      " 20  Kensington & Chelsea  306 non-null    object        \n",
      " 21  Kingston upon Thames  306 non-null    object        \n",
      " 22  Lambeth               306 non-null    object        \n",
      " 23  Lewisham              306 non-null    object        \n",
      " 24  Merton                306 non-null    object        \n",
      " 25  Newham                306 non-null    object        \n",
      " 26  Redbridge             306 non-null    object        \n",
      " 27  Richmond upon Thames  306 non-null    object        \n",
      " 28  Southwark             306 non-null    object        \n",
      " 29  Sutton                306 non-null    object        \n",
      " 30  Tower Hamlets         306 non-null    object        \n",
      " 31  Waltham Forest        306 non-null    object        \n",
      " 32  Wandsworth            306 non-null    object        \n",
      " 33  Westminster           306 non-null    object        \n",
      " 34  Unnamed: 34           0 non-null      float64       \n",
      " 35  Inner London          306 non-null    object        \n",
      " 36  Outer London          306 non-null    object        \n",
      " 37  Unnamed: 37           0 non-null      float64       \n",
      " 38  NORTH EAST            306 non-null    object        \n",
      " 39  NORTH WEST            306 non-null    object        \n",
      " 40  YORKS & THE HUMBER    306 non-null    object        \n",
      " 41  EAST MIDLANDS         306 non-null    object        \n",
      " 42  WEST MIDLANDS         306 non-null    object        \n",
      " 43  EAST OF ENGLAND       306 non-null    object        \n",
      " 44  LONDON                306 non-null    object        \n",
      " 45  SOUTH EAST            306 non-null    object        \n",
      " 46  SOUTH WEST            306 non-null    object        \n",
      " 47  Unnamed: 47           0 non-null      float64       \n",
      " 48  England               306 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(3), object(45)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tE9Sqt9-oAta"
   },
   "source": [
    "**2.2. Cleaning the data**\n",
    "\n",
    "You might find you need to transpose your dataframe, check out what its row indexes are, and reset the index. You  also might find you need to assign the values of the first row to your column headings  . (Hint: recall the .columns feature of DataFrames, as well as the iloc[] method).\n",
    "\n",
    "Don't be afraid to use StackOverflow for help  with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(how='all', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['City of London'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Unnamed: 0': 'Date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[1:, 'Date': 'Westminster']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1uLbJAsoIjK"
   },
   "source": [
    "**2.3. Cleaning the data (part 2)**\n",
    "\n",
    "You might we have to **rename** a couple columns. How do you do this? The clue's pretty bold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GKkmn1AnoVZS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Barking & Dagenham', 'Barnet', 'Bexley', 'Brent', 'Bromley',\n",
       "       'Camden', 'Croydon', 'Ealing', 'Enfield', 'Greenwich', 'Hackney',\n",
       "       'Hammersmith & Fulham', 'Haringey', 'Harrow', 'Havering', 'Hillingdon',\n",
       "       'Hounslow', 'Islington', 'Kensington & Chelsea', 'Kingston upon Thames',\n",
       "       'Lambeth', 'Lewisham', 'Merton', 'Newham', 'Redbridge',\n",
       "       'Richmond upon Thames', 'Southwark', 'Sutton', 'Tower Hamlets',\n",
       "       'Waltham Forest', 'Wandsworth', 'Westminster'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jy8BzXHmoWEw"
   },
   "source": [
    "**2.4.Transforming the data**\n",
    "\n",
    "Remember what Wes McKinney said about tidy data? \n",
    "\n",
    "You might need to **melt** your DataFrame here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "S2wM0qLuo2Zt"
   },
   "outputs": [],
   "source": [
    "data = pd.melt(data, id_vars = 'Date', var_name='District', value_name='Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZcR4IHbcpOaq"
   },
   "outputs": [],
   "source": [
    "data.Price = data.Price.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9760 entries, 0 to 9759\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Date      9760 non-null   datetime64[ns]\n",
      " 1   District  9760 non-null   object        \n",
      " 2   Price     9760 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 228.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knLUXHLypOtw"
   },
   "source": [
    "**2.5. Cleaning the data (part 3)**\n",
    "\n",
    "Do we have an equal number of observations in the ID, Average Price, Month, and London Borough columns? Remember that there are only 32 London Boroughs. How many entries do you have in that column? \n",
    "\n",
    "Check out the contents of the London Borough column, and if you find null values, get rid of them however you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BnvTW5a3p0fC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.District.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 Answering the Question**\n",
    "\n",
    "Which borough of London has seen the greatest average increase in housing prices over\n",
    "the (approximately) two decades covered by the dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "e0DF92cyqnu8"
   },
   "outputs": [],
   "source": [
    "data['year'] = pd.DatetimeIndex(data.Date).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_20_yrs = data.loc[data.year >= 2001].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_20_yrs = last_20_yrs.groupby(['District', 'year']).Price.mean().reset_index().rename(columns={'Price': 'avg_price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District</th>\n",
       "      <th>year</th>\n",
       "      <th>avg_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.866406e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>2002</td>\n",
       "      <td>1.122219e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>2003</td>\n",
       "      <td>1.424989e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>2004</td>\n",
       "      <td>1.581760e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>2005</td>\n",
       "      <td>1.633608e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>Westminster</td>\n",
       "      <td>2016</td>\n",
       "      <td>9.955434e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Westminster</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.064772e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>Westminster</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.020025e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>Westminster</td>\n",
       "      <td>2019</td>\n",
       "      <td>9.553525e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>Westminster</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.002810e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               District  year     avg_price\n",
       "0    Barking & Dagenham  2001  8.866406e+04\n",
       "1    Barking & Dagenham  2002  1.122219e+05\n",
       "2    Barking & Dagenham  2003  1.424989e+05\n",
       "3    Barking & Dagenham  2004  1.581760e+05\n",
       "4    Barking & Dagenham  2005  1.633608e+05\n",
       "..                  ...   ...           ...\n",
       "635         Westminster  2016  9.955434e+05\n",
       "636         Westminster  2017  1.064772e+06\n",
       "637         Westminster  2018  1.020025e+06\n",
       "638         Westminster  2019  9.553525e+05\n",
       "639         Westminster  2020  1.002810e+06\n",
       "\n",
       "[640 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_20_yrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_20_yrs['pt_change'] = last_20_yrs.groupby('District').avg_price.pct_change(periods=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District</th>\n",
       "      <th>pt_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Hackney</td>\n",
       "      <td>2.71559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    District  pt_change\n",
       "219  Hackney    2.71559"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_20_yrs.loc[last_20_yrs.pt_change == last_20_yrs.pt_change.max(), ['District','pt_change']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzYUI7FxJpgv"
   },
   "source": [
    "### 4. Conclusion\n",
    "\n",
    "In the last 20 years, the burrough that has seen the greatest change in average housing prices is Hackney.\n",
    "\n",
    "This was concluded by following these steps:\n",
    "\n",
    "1. Finding the average prices per burrough per year\n",
    "2. Grouping by district and applying the pandas function 'pct_change' to each group\n",
    "3. Adding 'percent change' column to dataframe\n",
    "4. Filtering the dataframe to only show the one row with the greatest prcnt change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
